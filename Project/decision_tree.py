# -*- coding: utf-8 -*-
"""decision tree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Nx-mlp9vw53xyh7XnvGgTdjhwH92d0po
"""

# Step 1: Import required libraries

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, _tree
from sklearn.metrics import accuracy_score, classification_report

# Step 2: Load your preprocessed dataset
# Make sure the file is in the same folder as your notebook, or give the full path.

df = pd.read_csv("D:\DataMining\projectphase2\Loan-prediction\Project\Cleaned_Loan_Train_Data.csv")

# Look at the first few rows
df.head()

df.columns

# Step 3: Separate features (X) and target (y)

TARGET_COL = "Loan_Status"

X = df.drop(columns=[TARGET_COL])
y = df[TARGET_COL]

print("Feature columns:", list(X.columns))
print("Target sample values:", y.unique())

# Step 4: Split the data into training and testing sets

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,      # 20% for testing
    random_state=42,    # for reproducibility
    stratify=y          # keeps same 0/1 ratio in train and test
)

dt = DecisionTreeClassifier(
    criterion="entropy",
    max_depth=5,          # prevents overfitting
    min_samples_split=10, # no splits for tiny groups
    min_samples_leaf=5,   # ensures smooth leaves
    random_state=42
)


dt.fit(X_train, y_train)

# Step 6: Evaluate the model

y_pred = dt.predict(X_test)

print("Accuracy on test set:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))

# Step 7.1: Function to print the decision tree as Yes/No rules

def print_yes_no_tree(clf, feature_names, target_names=None, indent="  "):
    """
    Prints a decision tree as nested Yes/No questions.

    clf : trained DecisionTreeClassifier
    feature_names : list of feature names (X.columns)
    target_names : optional list of class names, e.g. ["Not Approved", "Approved"]
    indent : indentation string for each depth level
    """
    tree_ = clf.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]

    # If no target names given, use the class labels directly
    if target_names is None:
        target_names = [str(c) for c in clf.classes_]

    def recurse(node, depth):
        prefix = indent * depth

        # If leaf node
        if tree_.feature[node] == _tree.TREE_UNDEFINED:
            class_idx = tree_.value[node].argmax()
            class_name = target_names[class_idx]
            print(f"{prefix}=> Predict: {class_name} "
                  f"(samples = {tree_.n_node_samples[node]})")
        else:
            name = feature_name[node]
            threshold = tree_.threshold[node]

            # Ask the question at this node
            print(f"{prefix}Is {name} <= {threshold:.3f}?")

            # YES branch (left child)
            print(f"{prefix}├─ Yes:")
            recurse(tree_.children_left[node], depth + 1)

            # NO branch (right child)
            print(f"{prefix}└─ No:")
            recurse(tree_.children_right[node], depth + 1)

    # Start from the root (node 0)
    recurse(0, 0)

# Step 7.2: Call the function to print the Yes/No decision tree

feature_names = list(X.columns)

# For your dataset: 0 = Not Approved, 1 = Approved
target_names = ["Not Approved", "Approved"]

print_yes_no_tree(dt, feature_names=feature_names, target_names=target_names)

from sklearn import tree
import matplotlib.pyplot as plt

plt.figure(figsize=(25, 10))
tree.plot_tree(
    dt,
    filled=True,
    rounded=True,
    feature_names=X.columns,
    class_names=["Not Approved", "Approved"]
)
plt.show()