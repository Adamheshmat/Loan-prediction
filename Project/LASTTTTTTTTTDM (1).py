# -*- coding: utf-8 -*-
"""LASTTTTTTTTTDM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AbCR0HmGHaK4Zjvk27xHHuxgopwpG8JC
"""

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, LabelEncoder


import seaborn as sns
import matplotlib.pyplot as plt

Data_set=pd.read_csv("Train data.csv")
# Remove Loan_ID because it's not a predictive feature
if 'Loan_ID' in Data_set.columns:
    Data_set.drop(columns=['Loan_ID'], inplace=True)

print(Data_set)

if 'Credit_History' in Data_set.columns:
    Data_set['Credit_History'] = Data_set['Credit_History'].astype('object')

"""### Checking for Skewness and Choosing Outlier Detection Method

Before detecting outliers, it's important to understand the distribution of the numerical features. If the data is skewed, methods like the Z-score, which assume a normal distribution, might not be the best approach. The Interquartile Range (IQR) method, on the other hand, is less sensitive to the distribution and is generally more robust for skewed data.

Let's visualize the distributions of the numerical features to check for skewness.
"""

numeric_cols_for_plot = Data_set.select_dtypes(include=np.number).columns.tolist()

if 'Loan_Status' in numeric_cols_for_plot:
    numeric_cols_for_plot.remove('Loan_Status')

print("Plotting distributions for numeric columns to check for skewness:")

for col in numeric_cols_for_plot:
    plt.figure(figsize=(8, 4))
    sns.histplot(Data_set[col], kde=True)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()

"""As you can see from the plots above, many of the numerical features are skewed (e.g., ApplicantIncome, CoapplicantIncome, LoanAmount). This skewness supports the use of the IQR method for outlier detection, as it does not assume a normal distribution like the Z-score method does."""

number_cols = Data_set.select_dtypes(exclude=['object']).columns.tolist()
#print(number_cols)
df=Data_set[number_cols]
#print(df)
imp_mean=SimpleImputer(missing_values=np.nan,strategy='mean')
imp_mean.fit(df)
df=imp_mean.transform(df)
df = pd.DataFrame(df, columns=number_cols)
np.set_printoptions(suppress=True)
pd.set_option('display.float_format', '{:.2f}'.format)
print(df.head())
#df.to_csv("cleaned_numeric_data.csv", index=False)

category_cols = Data_set.select_dtypes(include=['object']).columns.tolist()
dc=Data_set[category_cols]
#print(dc)
imp_mode=SimpleImputer(missing_values=np.nan,strategy='most_frequent')
imp_mode.fit(dc)
dc=imp_mode.transform(dc)

print(dc)

Data_set[number_cols]=df
Data_set[category_cols]=dc
print(Data_set)
#Data_set.to_csv("Cleaned.csv",index=False, encoding='utf-8', float_format='%.2f')

normalizer=MinMaxScaler(feature_range=(0,1))
norm_data=normalizer.fit_transform(df)
df_norm = pd.DataFrame(norm_data, columns=df.columns, index=df.index)
Data_set[number_cols]=norm_data
print(Data_set)
#Data_set.to_csv("cleaned_normalize3.csv")

def detect_outliers_iqr(df, column):
    """Return outlier rows and boundaries using IQR method."""
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    outliers = df[(df[column] < lower) | (df[column] > upper)]
    return outliers, lower, upper

print("\n=== OUTLIER DETECTION RESULTS ===")

skip_cols = ['Loan_Amount_Term']

print("\n=== OUTLIER DETECTION AND REMOVAL RESULTS ===")
initial_shape = Data_set.shape
print("DataFrame shape before outlier removal:", initial_shape)

for col in number_cols:
    if col in skip_cols:
        continue
    if Data_set[col].nunique() > 5:
        outliers, lower, upper = detect_outliers_iqr(Data_set, col)
        print(f"\n Column: {col}")
        print(f"Lower bound: {lower:.2f} | Upper bound: {upper:.2f}")
        print(f"Outliers detected: {len(outliers)}")


        print(outliers[[col]])


        plt.figure(figsize=(6, 2))
        sns.boxplot(x=Data_set[col], color='red')
        plt.title(f"Boxplot for {col}")
        plt.show()


        outliers_to_remove = Data_set[(Data_set[col] < lower) | (Data_set[col] > upper)]
        Data_set = Data_set.drop(outliers_to_remove.index).copy()
        print(f"Removed {len(outliers_to_remove)} outliers from column: {col}")


print("\nDataFrame shape after outlier removal:", Data_set.shape)

cat_cols = Data_set.select_dtypes(include=['object']).columns.tolist()
print("Categorical columns before encoding:", cat_cols)

if 'Dependents' in Data_set.columns:
    Data_set['Dependents'] = Data_set['Dependents'].replace('3+', 3)
    Data_set['Dependents'] = pd.to_numeric(Data_set['Dependents'], errors='coerce')

binary_cols = ['Gender', 'Married', 'Education', 'Self_Employed', 'Loan_Status','Credit_History']

le = LabelEncoder()
for col in binary_cols:
    if col in Data_set.columns:
        Data_set[col] = le.fit_transform(Data_set[col])

multi_cols = ['Property_Area']
Data_set = pd.get_dummies(Data_set, columns=multi_cols, drop_first=True)

print("\nEncoding complete!")
print(Data_set.head())
print("\nData types after encoding:")
print(Data_set.dtypes)

for col in ['Property_Area_Semiurban', 'Property_Area_Urban']:
    if col in Data_set.columns:
        Data_set[col] = Data_set[col].astype(int)

corr_matrix = Data_set.select_dtypes(include=['number']).corr()

plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Heatmap of All Encoded Features")
plt.show()

target_corr = corr_matrix['Loan_Status'].sort_values(ascending=False)
print("Correlation of features with Loan_Status:")
pd.set_option('display.float_format', '{:.6f}'.format)
print(target_corr)
pd.reset_option('display.float_format')

# ==========================
# SAVE FINAL CLEANED DATASET
# ==========================

# Make sure Loan_Status is numeric (required for models)
Data_set['Loan_Status'] = Data_set['Loan_Status'].astype(int)

# Reset index after outlier removal
Data_set = Data_set.reset_index(drop=True)

# Save cleaned file
Data_set.to_csv("Cleaned_Loan_Train_Data.csv", index=False)

print("\n===============================")
print("Final cleaned dataset created:")
print("Saved as: Cleaned_Loan_Train_Data.csv")
print("Shape:", Data_set.shape)
print("===============================")

